{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code for analysis of crispresso editing information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "import os\n",
    "warnings.filterwarnings('ignore')\n",
    "plt.rc('font', family='Helvetica')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crispresso_compiler(samp, sample_id, folder_path):\n",
    "    \"\"\" \n",
    "    Takes in list of sample names (see cell above)\n",
    "    Returns compiled dictionary of dataframes containing editing information for each sensor\n",
    "    \n",
    "    Includes:\n",
    "    1. corr_perc = pure correct editing\n",
    "    2. target_base_edit_perc = target base editing perc (including edits with bystander editing)\n",
    "    3. wt_perc\n",
    "    4. byproduct information (indels, substitutions, ambiguous)\n",
    "    \"\"\"\n",
    "\n",
    "    df_edits = []\n",
    "    for k in samp: \n",
    "        \n",
    "        try:\n",
    "            concated = pd.read_csv(f'{folder_path}/{k}_crispresso_aggregated.csv')\n",
    "\n",
    "        except:\n",
    "            concated = pd.read_csv(f'{folder_path}/{k}_crispresso_aggregated_v2.csv')\n",
    "            \n",
    "        concated = concated.fillna(0)\n",
    "\n",
    "        #somehow wasn't able to find the initial set of code that I used for this...\n",
    "\n",
    "        #go through all of the samples and do it step by step\n",
    "        sample_ids = []\n",
    "        #sample_num = []\n",
    "        rii = []\n",
    "        raaa = []\n",
    "        r_lowqual = []\n",
    "        ra_hdr = []\n",
    "        ra_wt = []\n",
    "        r_unaligned = []\n",
    "        no_edit = []\n",
    "        correct = []\n",
    "        target_base_editing = []\n",
    "        byproduct_all = []\n",
    "        byproduct_indel = []\n",
    "        byproduct_sub = []\n",
    "        byproduct_ambig = []\n",
    "        for i in np.unique(concated['Guide_ID']):\n",
    "            sample_ids.append(i)\n",
    "\n",
    "            subset = concated[concated['Guide_ID']==i]\n",
    "\n",
    "            wt = subset[subset['Amplicon']=='Reference']\n",
    "            edit = subset[subset['Amplicon']=='HDR']\n",
    "\n",
    "            #sample_num.append(wt['sample_num'].values[0])\n",
    "            rii1 = wt['Reads_in_input'].values[0]\n",
    "            r1 = wt['Reads_aligned_all_amplicons'].values[0]\n",
    "            rii.append(rii1)\n",
    "            raaa.append(r1)\n",
    "            r_lowqual.append(rii1-r1)\n",
    "\n",
    "            r2 = edit['Reads_aligned'].values[0]\n",
    "            r3 = wt['Reads_aligned'].values[0]\n",
    "            ra_hdr.append(r2)\n",
    "            ra_wt.append(r3)\n",
    "            r_unaligned.append(r1 - (r2+r3))\n",
    "\n",
    "            no_edit.append(wt['Unmodified'].values[0])\n",
    "            correct.append(edit['Unmodified'].values[0])\n",
    "            target_base_editing.append(edit['Modified'].values[0] + edit['Unmodified'].values[0])\n",
    "\n",
    "            byprod_all = wt['Modified'].values[0] + edit['Modified'].values[0] + (r1 - (r2+r3)) #add unaligned reads\n",
    "            sub_all = wt['Only Substitutions'].values[0] + edit['Only Substitutions'].values[0]\n",
    "            indel_all = wt['Only Deletions'].values[0] + wt['Only Insertions'].values[0] + wt['Insertions and Deletions'].values[0] + edit['Only Deletions'].values[0] + edit['Only Insertions'].values[0] + edit['Insertions and Deletions'].values[0]\n",
    "            ambig_all = byprod_all - sub_all - indel_all\n",
    "\n",
    "            byproduct_all.append(byprod_all)\n",
    "            byproduct_indel.append(indel_all)\n",
    "            byproduct_sub.append(sub_all)\n",
    "            byproduct_ambig.append(ambig_all)\n",
    "\n",
    "\n",
    "        cols = [\"Guide_ID\", \"Reads_in_input\",\"Reads_lowqual\", \"Reads_aligned_all_amplicons\",\"Reads_aligned_WT\", \"Reads_aligned_HDR\", \"Reads_unaligned\", \"WT\",\"correct_edit\", \"target_base_edit\", \"byproduct_all\",\"byproduct_INDEL\",\"byproduct_sub\",\"byproduct_ambiguous\"]\n",
    "        col_vals = [ sample_ids, rii, r_lowqual, raaa, ra_wt, ra_hdr, r_unaligned, no_edit, correct, target_base_editing, byproduct_all, byproduct_indel, byproduct_sub, byproduct_ambig]\n",
    "\n",
    "        out = pd.DataFrame(dict(zip(cols, col_vals)))\n",
    "        out['corr_perc'] = 100*(out['correct_edit']/out['Reads_aligned_all_amplicons'])\n",
    "        out['target_base_edit_perc'] = 100*(out['target_base_edit']/out['Reads_aligned_all_amplicons'])\n",
    "        out['WT_perc'] = 100*(out['WT']/out['Reads_aligned_all_amplicons'])\n",
    "        out['byproduct_all_perc'] =  100*(out['byproduct_all']/out['Reads_aligned_all_amplicons'])\n",
    "        out['byproduct_INDEL_perc'] =  100*(out['byproduct_INDEL']/out['Reads_aligned_all_amplicons'])\n",
    "        out['byproduct_sub_perc'] =  100*(out['byproduct_sub']/out['Reads_aligned_all_amplicons'])\n",
    "        out['byproduct_ambiguous_perc'] =100*(out['byproduct_ambiguous']/out['Reads_aligned_all_amplicons'])\n",
    "        out = out.fillna(0)\n",
    "\n",
    "        df_edits.append(out)\n",
    "\n",
    "    edit_dict = dict(zip(sample_id, df_edits))\n",
    "\n",
    "    return edit_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MLE_merge(edit_dict, samps_to_merge, new_name):\n",
    "    \"\"\" \n",
    "    combine replicates to generate best estimate of sensor editing\n",
    "    only works for combinations of 3 replicates (could be modified)\n",
    "\n",
    "    MODIFIED TO WORK FOR MULTIPLE REPLICATES\n",
    "    \"\"\"\n",
    "    cols_to_add = ['Reads_in_input', 'Reads_lowqual',\n",
    "       'Reads_aligned_all_amplicons', 'Reads_aligned_WT', 'Reads_aligned_HDR',\n",
    "       'Reads_unaligned', 'WT', 'correct_edit', 'target_base_edit',\n",
    "       'byproduct_all', 'byproduct_INDEL', 'byproduct_sub',\n",
    "       'byproduct_ambiguous',]\n",
    "    \n",
    "    comb_holder = []\n",
    "    for k in samps_to_merge:\n",
    "        \n",
    "        a = edit_dict[k[0]]\n",
    "        comb = a[cols_to_add]\n",
    "\n",
    "        for jj in k[1:]:\n",
    "            print(jj)\n",
    "            j_df = edit_dict[jj]\n",
    "            comb+=j_df[cols_to_add]\n",
    "        \n",
    "        #a = edit_dict[k[0]]\n",
    "        #b = edit_dict[k[1]]\n",
    "        #c = edit_dict[k[2]]\n",
    "\n",
    "        #check that guide indeces match\n",
    "        #assert list(a['Guide_ID'])==list(b['Guide_ID'])==list(c['Guide_ID']), 'indexes dont match'\n",
    "\n",
    "        #a2 = a[cols_to_add]\n",
    "        #b2 = b[cols_to_add]\n",
    "        #c2 = c[cols_to_add]\n",
    "\n",
    "        #comb = a2+b2+c2\n",
    "\n",
    "        comb['Guide_ID'] = a['Guide_ID']\n",
    "\n",
    "        #and reorganize columns\n",
    "        col_order = ['Guide_ID'] + cols_to_add\n",
    "        out = comb[col_order]\n",
    "\n",
    "        #and then calcualte percentages\n",
    "        out['corr_perc'] = 100*(out['correct_edit']/out['Reads_aligned_all_amplicons'])\n",
    "        out['target_base_edit_perc'] = 100*(out['target_base_edit']/out['Reads_aligned_all_amplicons'])\n",
    "        out['WT_perc'] = 100*(out['WT']/out['Reads_aligned_all_amplicons'])\n",
    "        out['byproduct_all_perc'] =  100*(out['byproduct_all']/out['Reads_aligned_all_amplicons'])\n",
    "        out['byproduct_INDEL_perc'] =  100*(out['byproduct_INDEL']/out['Reads_aligned_all_amplicons'])\n",
    "        out['byproduct_sub_perc'] =  100*(out['byproduct_sub']/out['Reads_aligned_all_amplicons'])\n",
    "        out['byproduct_ambiguous_perc'] =100*(out['byproduct_ambiguous']/out['Reads_aligned_all_amplicons'])\n",
    "        out = out.fillna(0)\n",
    "\n",
    "        comb_holder.append(out)\n",
    "\n",
    "    out_dict = dict(zip(new_name, comb_holder))\n",
    "\n",
    "    return out_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "samp_CBE = ['D24-12799-6840R_guide_split_BARCODES',\n",
    " 'D24-12800-6840R_guide_split_BARCODES',\n",
    " 'D24-12801-6840R_guide_split_BARCODES',\n",
    " 'D24-12802-6840R_guide_split_BARCODES',\n",
    " 'D24-12803-6840R_guide_split_BARCODES',\n",
    " 'D24-12804-6840R_guide_split_BARCODES',\n",
    " 'D24-12805-6840R_guide_split_BARCODES',\n",
    " 'D24-12806-6840R_guide_split_BARCODES',\n",
    " 'D24-12807-6840R_guide_split_BARCODES',\n",
    " 'D24-12808-6840R_guide_split_BARCODES',\n",
    " 'D24-12809-6840R_guide_split_BARCODES',\n",
    " 'D24-12810-6840R_guide_split_BARCODES',\n",
    " 'D24-12811-6840R_guide_split_BARCODES',\n",
    " 'D24-12812-6840R_guide_split_BARCODES',\n",
    " 'D24-12813-6840R_guide_split_BARCODES',\n",
    " 'D24-12814-6840R_guide_split_BARCODES',\n",
    " 'D24-12815-6840R_guide_split_BARCODES',\n",
    " 'D24-12816-6840R_guide_split_BARCODES',\n",
    " 'D24-12817-6840R_guide_split_BARCODES',\n",
    " 'D24-12818-6840R_guide_split_BARCODES',\n",
    " 'D24-12819-6840R_guide_split_BARCODES',\n",
    " 'D24-12820-6840R_guide_split_BARCODES',\n",
    " 'D24-12821-6840R_guide_split_BARCODES',\n",
    " 'D24-12822-6840R_guide_split_BARCODES',\n",
    " 'D24-12823-6840R_guide_split_BARCODES',\n",
    " 'D24-12824-6840R_guide_split_BARCODES',\n",
    " 'D24-12825-6840R_guide_split_BARCODES',\n",
    " 'D24-12826-6840R_guide_split_BARCODES',\n",
    " 'D24-12827-6840R_guide_split_BARCODES',\n",
    " 'D24-12828-6840R_guide_split_BARCODES',\n",
    " 'D24-12829-6840R_guide_split_BARCODES',\n",
    " 'D24-12830-6840R_guide_split_BARCODES',\n",
    " 'D24-12831-6840R_guide_split_BARCODES',\n",
    " 'D24-12832-6840R_guide_split_BARCODES',\n",
    " 'D24-12833-6840R_guide_split_BARCODES',\n",
    " 'D24-12834-6840R_guide_split_BARCODES',\n",
    " 'D24-12835-6840R_guide_split_BARCODES',\n",
    " 'D24-12836-6840R_guide_split_BARCODES',\n",
    " 'D24-12837-6840R_guide_split_BARCODES']\n",
    "\n",
    "sample_id_CBE = ['spleen1', 'spleen2','spleen3','spleen4','spleen5', 'spleen6', 'spleen7', 'spleen8', 'spleen9', 'bonemarrow1','bonemarrow2','bonemarrow3',\n",
    "            'bonemarrow4','bonemarrow5', 'bonemarrow6','bonemarrow7','bonemarrow8', 'bonemarrow9',\n",
    "             'bonemarrow10','meninges1','meninges2','meninges3','meninges4','meninges5', 'meninges6', 'meninges7',\n",
    "             'meninges8', 'meninges9', 'meninges10',\n",
    "            'input_rep1', 'input_rep2', 'input_rep3', 'd5_rep1', 'd5_rep2', 'd5_rep3', 'd15_rep1',\n",
    "            'd15_rep2', 'd15_rep3', 'plasmidlib']\n",
    "\n",
    "\n",
    "samp_ABE = ['D24-12774-6848T_guide_split_BARCODES',\n",
    " 'D24-12775-6848T_guide_split_BARCODES',\n",
    " 'D24-12776-6848T_guide_split_BARCODES',\n",
    " 'D24-12777-6848T_guide_split_BARCODES',\n",
    " 'D24-12778-6848T_guide_split_BARCODES',\n",
    " 'D24-12779-6848T_guide_split_BARCODES',\n",
    " 'D24-12780-6848T_guide_split_BARCODES',\n",
    " 'D24-12781-6848T_guide_split_BARCODES',\n",
    " 'D24-12782-6848T_guide_split_BARCODES',\n",
    " 'D24-12783-6848T_guide_split_BARCODES',\n",
    " 'D24-12784-6848T_guide_split_BARCODES',\n",
    " 'D24-12785-6848T_guide_split_BARCODES',\n",
    " 'D24-12786-6848T_guide_split_BARCODES',\n",
    " 'D24-12787-6848T_guide_split_BARCODES',\n",
    " 'D24-12788-6848T_guide_split_BARCODES',\n",
    " 'D24-12789-6848T_guide_split_BARCODES',\n",
    " 'D24-12790-6848T_guide_split_BARCODES',\n",
    " 'D24-12791-6848T_guide_split_BARCODES',\n",
    " 'D24-12792-6848T_guide_split_BARCODES',\n",
    " 'D24-12793-6848T_guide_split_BARCODES',\n",
    " 'D24-12794-6848T_guide_split_BARCODES',\n",
    " 'D24-12795-6848T_guide_split_BARCODES',\n",
    " 'D24-12796-6848T_guide_split_BARCODES',\n",
    " 'D24-12797-6848T_guide_split_BARCODES',\n",
    " 'D24-12798-6848T_guide_split_BARCODES',]\n",
    "\n",
    "sample_id_ABE = ['spleen1', 'spleen2','spleen3','spleen4','spleen5', 'bonemarrow1','bonemarrow2','bonemarrow3',\n",
    "            'bonemarrow4','bonemarrow5','meninges1','meninges2','meninges3','meninges4','meninges5',\n",
    "            'input_rep1', 'input_rep2', 'input_rep3', 'd5_rep1', 'd5_rep2', 'd5_rep3', 'd15_rep1',\n",
    "            'd15_rep2', 'd15_rep3', 'plasmidlib']\n",
    "\n",
    "\n",
    "ABE_samples = pd.DataFrame(dict(zip(['file_name', 'sample'], [samp_ABE, sample_id_ABE])))\n",
    "CBE_samples = pd.DataFrame(dict(zip(['file_name', 'sample'], [samp_CBE, sample_id_CBE])))\n",
    "\n",
    "ABE_samp_dict = dict(zip(samp_ABE, sample_id_ABE))\n",
    "CBE_samp_dict = dict(zip(samp_CBE, sample_id_CBE))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ABE quantification and MLE generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samp = list(ABE_samp_dict.keys())\n",
    "sample_id = list(ABE_samp_dict.values())\n",
    "folder_path = '240807Hem_ABE/crispresso'\n",
    "ABE_edit_dict = crispresso_compiler(samp, sample_id, folder_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samps_to_merge = [['spleen1',\n",
    " 'spleen2',\n",
    " 'spleen3',\n",
    " 'spleen4',\n",
    " 'spleen5',],\n",
    " ['bonemarrow1',\n",
    " 'bonemarrow2',\n",
    " 'bonemarrow3',\n",
    " 'bonemarrow4',\n",
    " 'bonemarrow5',],\n",
    " ['meninges1',\n",
    " 'meninges2',\n",
    " 'meninges3',\n",
    " 'meninges4',\n",
    " 'meninges5',],\n",
    " ['input_rep1',\n",
    " 'input_rep2',\n",
    " 'input_rep3',],\n",
    " ['d5_rep1',\n",
    " 'd5_rep2',\n",
    " 'd5_rep3',],\n",
    " ['d15_rep1',\n",
    " 'd15_rep2',\n",
    " 'd15_rep3',],\n",
    " ['plasmidlib']]\n",
    "\n",
    "new_name = ['spleen', 'bonemarrow', 'meninges', 'input', 'd5', 'd15', 'plasmid']\n",
    "out_MLE = MLE_merge(ABE_edit_dict, samps_to_merge, new_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CBE quantification and MLE generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samp = list(CBE_samp_dict.keys())\n",
    "sample_id = list(CBE_samp_dict.values())\n",
    "folder_path = '240807HemA_CBE/crispresso'\n",
    "CBE_edit_dict = crispresso_compiler(samp, sample_id, folder_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#and then run it for the legacy guides that were quantified later\n",
    "samp = list(CBE_samp_dict.keys())\n",
    "sample_id = list(CBE_samp_dict.values())\n",
    "folder_path = '240807HemA_CBE/crispresso_legacy'\n",
    "CBE_edit_dict_legacy = crispresso_compiler(samp, sample_id, folder_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#and updating the results so that the legacy guides have editing quantified\n",
    "sample_id = list(CBE_samp_dict.values())\n",
    "\n",
    "new_dfs = []\n",
    "for sample_considered in sample_id:\n",
    "    a = CBE_edit_dict_legacy[sample_considered]\n",
    "\n",
    "    b = CBE_edit_dict[sample_considered]\n",
    "\n",
    "    b = b[~b['Guide_ID'].isin(list(a['Guide_ID']))]\n",
    "\n",
    "    new = pd.concat((b,a)).sort_values(by='Guide_ID')\n",
    "    new_dfs.append(new)\n",
    "\n",
    "\n",
    "CBE_edit_dict_new = dict(zip(sample_id, new_dfs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samps_to_merge = [['spleen1',\n",
    " 'spleen2',\n",
    " 'spleen3',\n",
    " 'spleen4',\n",
    " 'spleen5',\n",
    " 'spleen6',\n",
    " 'spleen7',\n",
    " 'spleen8',\n",
    " 'spleen9',],\n",
    " ['bonemarrow1',\n",
    " 'bonemarrow2',\n",
    " 'bonemarrow3',\n",
    " 'bonemarrow4',\n",
    " 'bonemarrow5',\n",
    " 'bonemarrow6',\n",
    " 'bonemarrow7',\n",
    " 'bonemarrow8',\n",
    " 'bonemarrow9',\n",
    " 'bonemarrow10',],\n",
    " ['meninges1',\n",
    " 'meninges2',\n",
    " 'meninges3',\n",
    " 'meninges4',\n",
    " 'meninges5',\n",
    " 'meninges6',\n",
    " 'meninges7',\n",
    " 'meninges8',\n",
    " 'meninges9',\n",
    " 'meninges10',],\n",
    " ['input_rep1',\n",
    " 'input_rep2',\n",
    " 'input_rep3',],\n",
    " ['d5_rep1',\n",
    " 'd5_rep2',\n",
    " 'd5_rep3',],\n",
    " ['d15_rep1',\n",
    " 'd15_rep2',\n",
    " 'd15_rep3',],\n",
    " ['plasmidlib']]\n",
    "\n",
    "new_name = ['spleen', 'bonemarrow', 'meninges', 'input', 'd5', 'd15', 'plasmid']\n",
    "out_MLE_CBE = MLE_merge(CBE_edit_dict_new, samps_to_merge, new_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
